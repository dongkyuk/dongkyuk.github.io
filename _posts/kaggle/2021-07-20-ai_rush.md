---
title:  "Naver Clova AI Rush 2021 후기"
categories: kaggle
excerpt: AI Rush 2021
---
오랜만에 글을 올린다. 마지막 게시물 이후 정말 많은 일들이 있었는데, 그 중 하나였던 Naver Clova AI Rush 후기를 남기고자 한다.

기밀 유지 서약 때문에 자세한 사항은 disclose하기가 힘든점 양해를 바란다.

## 서류/코테

서류의 경우 과거 클로바 지원 시에 썼던걸 그대로 냈다. 주로 깃헙과 프로젝트 경험을 많이 중시 했던 것 같았다.

코딩테스트는 4문제 나왔는데, 전체적으로 쉬웠다. 과거 인턴십 면접 정도 느낌? (훈련소 입소 전 회식 후 취한 상태로 봐서 기억이..)

## Round 1

1라운드의 경우 총 5가지 과제 중 선택 후 진행이었는데, 나 같은 경우 육군 훈련소 때문에 열흘 정도 시간을 손해보고 일주일 전에 시작을 했기에 가장 빠르게 baseline을 구축하고 성과를 낼 수 있는 태스크를 선택했다.

그렇게 고른 것이 **CLOVA ML X**의 **스마트스토어 SKU단위 수요 예측**!

네이버 스마트스토어의 상품 수요 예측을 하는 꽤나 전형적인 time series regression 문제였다.

모델의 경우 lstm 모델을 5 fold ensemble을 했는데, 모델보다는 sparse data를 다루는 방식과 loss의 선정이 점수 향상의 킬링포인트였다.

운좋게도 1라운드는 **1등**으로 마무리를 할 수 있었다! :sunglasses:

## Round 2

2라운드에서 내가 가장 중요시한 것은 두가지였는데, 다음과 같았다

1. task가 지나치게 전형적이지 않고 재미있냐
2. 데이터 로딩, 전처리, 정제 등의 과정이 지나치게 많지는 않은가 (데이터의 품질?)

그렇게 고른 것이 8개의 과제 중 **CLOVA ML X**의 **대규모 쇼핑 데이터를 활용한 일반적인 유저 임베딩 추출**!

상품의 설명을 보고 같은 상품들을 클러스터링하는 문제이다. 약간 다르긴 하지만 이 [링크](https://d2.naver.com/helloworld/1264836)를 보면 대충 감이 올 것 같다.

이 주제를 고른 것은 당시 한참 siamese network, one/few shot learning 등에 관심이 많았는데, 주제가 내 관심사에 부합했고 한번도 경험해보지 못한 분야였기 때문이다.

최종적으로 만든 모델의 경우 사전 학습된 klue bert를 embedding간 cosine similarity의 arcface loss로 재학습시킨 모델이었다.

전처리의 경우 특수문자 제거 정도, 후처리의 경우 업스테이지의 yoonso, limerobot님이 하셨던 iterative neighborhood blending을 많이 참고했다. ([참조](https://www.kaggle.com/c/shopee-product-matching/discussion/238136))

아쉽게도 2라운드는 **4등**으로 마무리해 챌린저 상금은 놓치고 우수 참가자 채용 특전을 받을 수 있었다 (다만 복학 때문에..)

추후 내 솔루션을 다른 사람들과 비교하면서 부족한 점을 생각해보니 마지막 inference에서 similarity threshold를 너무 naive하게 tuning 한 것 같다 ㅎㅎ. 

## 시간이 있었다면

시간이 더 있었다면
- Bayesian Hyperparameter Tuning (batch size, embedding dimension, lr, arcfaceloss hyper param..)
- Postprocessing 실험
- 텍스트 전처리 심화
- 언어모델 ensemble 

정도를 할 예정이었다.

## 아쉬웠던 점

- 기술

2라운드에서 부족했던 점은 생각보다 sophisticated된 기술이 아니었다. 

말하자면 데이터와 평가 방식에 대해서 조금만 더 자세히 생각했다면 적용할 수 있는 것이었다. 

2라운드를 진행하면서 지나치게 elegant한 기술들과 sota method에 집중을 했는데, 간단한걸 놓친 것이다. 

일을 할때는 협업을 하면서 놓치지 않을 부분이었을텐데 한 방법론에 눈이 돌아가버린 폐해인가 싶기도 하고, 조금 더 차분히 문제에 대해 생각해보았다면 좋았을 것 같다. 

- 시간 관리
 
제출 수를 확인해보니, 다른 분들보다 현저히 적게 제출을 했다 (3,4배 가량). 

기본적으로 내 시간 관리가 미흡하지 않았나라는 생각이 든다. 바쁜 일(이직 등)과 많이 겹쳐서 스스로에게 엄격함이 부족했던 것 같다.

Data Science Competition들의 경우 시간 투자가 항상은 아니지만 많은 경우 정직하게 점수에 반영이 되는 것 같은데, 앞으로 주의할 부분이다.

## 느낀 점

굉장히 재밌었다. 

대회의 데이터가 실제로 네이버 서비스에서 나온 것이라는 점, kaggle 처럼 베이스라인 코드 및 자료가 상세히 주어지지 않았다는 점이 현업에서의 machine learning problem과 이 대회가 더 가깝게 느껴지게 했던 것 같다.

처음 접하는 분야들을 각종 논문과 자료들을 뒤적이면서 연구하고, 모든 과정에서 내가 주도적으로 관여했다는 점에서 굉장히 의미있는 대회였던 것 같다.

또한 이번 대회를 계기로 time series data도 다루어보고, nlp 찍먹도 해보고, metric learning이라는 분야도 공부하게 되었다. (metric learning의 경우 공부 블로그 [포스트](https://dongkyuk.github.io/study/metric-learning/)도 남겼다 ㅎㅎ)

## 마무리

상품도 받았다!

![Image](https://raw.githubusercontent.com/dongkyuk/dongkyuk.github.io/main/assets/images/airush.jpg)




