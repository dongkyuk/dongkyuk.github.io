---
title:  "LeNet"
categories: papers
excerpt: Gradient-Based Learning Applied to Document Recognition
---
![image](https://hoya012.github.io/assets/img/image_classification_guidebook/1.PNG)

처음 읽었던 딥러닝 논문이다.

위 이미지가 익숙한 사람이 많을 것 같다. 구조가 워낙 간단해 딥러닝 튜토리얼로도 많이 쓰이는 architecture이다.

현재 Vision쪽에 가장 많이 쓰이는 Convolutional Nerual Network이 처음 제안된 논문이고 저자인 Yann LeCun의 이름을 따 제안된 neural network를 LeNet이라고 부른다.

지금 생각해보니 처음 읽기에는 그닥 적합한 논문은 아닌 것 같다. 워낙 옛날 논문이라 문장들도 최신 논문들 처럼 간결하지가 않고 Reference를 제외해도 길이만 40페이지가 넘는다. (처음 읽었을 때 딥러닝 논문들이 다 이런줄 알고 걱정했던 기억이 난다 ㅎㅎ) 실제로도 저 LeNet architecture만 알고 논문을 읽은 사람은 별로 없는 것 같다. 

이 논문의 경우 Medium에 장문으로 영어 리뷰를 작성했는데, 더 자세한 리뷰를 참고 바란다. [링크](https://dongkyuk.medium.com/gradient-based-learning-applied-to-document-recognition-review-f73386b35491)

## 5줄 요약
이 논문은 IBM에서 손글씨 인식 연구를 한 내용인데, 내용은 다음과 같다 : 
- Convolutional Neural Network (합성곱 신경망)을 쓰자!
  - Local receptive fields (지역적 수용 영역)
    - 이미지에 지역적 정보를 추출해 topology 문제를 해결한다
  - Shared Weights (convolutional filter의 weight 공유)
    - 이미지의 translational equivariance를 활용해 파라미터 숫자를 획기적으로 줄였다
- Subsampling (Average Pooling)
  - 추출한 Feature Map에서 모든 정보가 필요한게 아니고, 오히려 지나치게 자세한 정보는 학습에 방해를 준다.
  - Pooling을 통해 Feature에서 전체적인 정보만을 가져간다
- Graph Transformer Networks (이 부분은 내용이 많아서 위 링크를 참고 바란다)
- 딥러닝의 밝은 미래~
  - 저자들은 논문에서 training data/computer 성능/딥러닝에 대한 이해가 좋아지면 모델의 성능 또한 매우 좋아질 것이라 예측했고, 현재 우리가 사는 세상을 보면 그 예상은 완벽히 맞았다 

## 후기
LeCun의 논문을 보면 CNN을 왜 사용하는지에 대한 근본적인 이해가 된다. 

SVM 등이 대세였던 시절에 나온 기념비적인 논문인만큼 딥러닝의 생생한 역사를 읽고 있는 듯한 재미도 있었다.

어쩌다 보니 5줄은 실패했다 ㅠㅠ 

